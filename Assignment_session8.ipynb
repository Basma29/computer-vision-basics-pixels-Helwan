{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Basma29/computer-vision-basics-pixels-Helwan/blob/main/Assignment_session8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSP-Intro to AI & Computer Vision\n",
        "\n",
        "# Assignment Session 8 - Real-Time Object Detection with OpenCV"
      ],
      "metadata": {
        "id": "T9EfxQMdxX-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **For the Important Files Run this cell**"
      ],
      "metadata": {
        "id": "wPBlnrN84ODA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "# --- MobileNet-SSD ---\n",
        "mobilenet_prototxt = \"https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/deploy.prototxt\"\n",
        "mobilenet_model = \"https://github.com/chuanqi305/MobileNet-SSD/raw/master/mobilenet_iter_73000.caffemodel\"\n",
        "\n",
        "urllib.request.urlretrieve(mobilenet_prototxt, \"mobilenet_deploy.prototxt\")\n",
        "urllib.request.urlretrieve(mobilenet_model, \"mobilenet_iter_73000.caffemodel\")\n",
        "\n",
        "# --- Face DNN Model ---\n",
        "face_prototxt = \"https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\"\n",
        "face_model = \"https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "\n",
        "urllib.request.urlretrieve(face_prototxt, \"deploy_face.prototxt\")\n",
        "urllib.request.urlretrieve(face_model, \"res10_300x300_ssd_iter_140000.caffemodel\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_0HeBuMp4Y3Y",
        "outputId": "ac2fc1d2-1aae-4a13-c351-035a7c4faa34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('res10_300x300_ssd_iter_140000.caffemodel',\n",
              " <http.client.HTTPMessage at 0x78cf3ad41c90>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1"
      ],
      "metadata": {
        "id": "OTm0m12rx2ul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Use Haar or DNN-based face detection to count how many faces are detected in the webcam feed and display the count on the video.\n",
        "\n",
        "\n",
        "1. Open the webcam using cv2.VideoCapture.\n",
        "\n",
        "2. Load the face detection model (Haar or DNN).\n",
        "\n",
        "3. Read each frame in a loop.\n",
        "\n",
        "4. Detect faces in the current frame.\n",
        "\n",
        "5. Count the number of detected faces.\n",
        "\n",
        "6. Display the count on the video using cv2.putText.\n",
        "\n"
      ],
      "metadata": {
        "id": "MCF3qh75yMja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter code here"
      ],
      "metadata": {
        "id": "fIlSavGBzM4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "O72UmjmzzQgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Start tracking an object using the CSRT tracker, and allow the user to switch to a different tracker (like KCF or MOSSE) by pressing keys during live webcam tracking.\n",
        "\n",
        "\n",
        "1. Open the webcam.\n",
        "\n",
        "2. Select an object to track.\n",
        "\n",
        "3. Start tracking with CSRT.\n",
        "\n",
        "4. In live video:\n",
        "\n",
        "  - Press k to switch to KCF.\n",
        "\n",
        "  - Press m to switch to MOSSE.\n",
        "\n",
        "5. Reinitialize the tracker after switching.\n",
        "\n",
        "6. Show the tracking box on screen.\n",
        "\n",
        "7. Exit when ESC is pressed."
      ],
      "metadata": {
        "id": "0dVyU7Q0zUXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter code here"
      ],
      "metadata": {
        "id": "LR_iuyui0Uun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3"
      ],
      "metadata": {
        "id": "cBpYIkzl0Wsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Track a colored object (like red), but instead of drawing — apply a visual effect (blur or edge detection) only on that region in real time.\n",
        "\n",
        "1. Open webcam video.\n",
        "\n",
        "2. Convert each frame to HSV color space.\n",
        "\n",
        "3. Create a mask for the target color (e.g. red).\n",
        "\n",
        "4. Find the region where the color exists.\n",
        "\n",
        "5. Apply an effect (like blur or Canny edge detection) only to that region.\n",
        "\n",
        "6. Combine the effect with the original frame.\n",
        "\n",
        "7. Display the final result in real time."
      ],
      "metadata": {
        "id": "5afg7zh50cha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter code here"
      ],
      "metadata": {
        "id": "1WGZy-HI04aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4"
      ],
      "metadata": {
        "id": "WnxRSVPC06Ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Build a Python program that performs real-time object detection on a video file using the pre-trained MobileNet-SSD model.\n",
        "\n",
        " 1. Load a pre-trained MobileNet-SSD model.\n",
        "\n",
        "2. Open a video file\n",
        "\n",
        "3. Detect objects using the model.\n",
        "\n",
        "4. Draw bounding boxes and show object names with confidence scores.\n",
        "\n",
        "5. Display the video with detections in real-time.\n",
        "\n",
        "6. Press Esc  to stop the program"
      ],
      "metadata": {
        "id": "A2-rQ_NT0992"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter code here"
      ],
      "metadata": {
        "id": "Wc6wd2D81zFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5"
      ],
      "metadata": {
        "id": "HBFTMv0_11IU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Face Zoom Live Filter (Like Instagram) When a face is detected, automatically zoom in on it.\n",
        "\n",
        "1. Open webcam\n",
        "\n",
        "2. Use Haar or DNN to detect faces in real-time.\n",
        "\n",
        "3. When a face is detected, crop the face region.\n",
        "\n",
        "4. Resize (zoom in) the cropped face using **cv2.resize**.\n",
        "\n",
        "5. Display the zoomed-in face in a separate window or overlay it back.\n",
        "\n",
        "6. Continuously update as the face moves.\n",
        "\n",
        "7. Exit when ESC is pressed.\n",
        "\n"
      ],
      "metadata": {
        "id": "jAEIKPCv14JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter code here"
      ],
      "metadata": {
        "id": "pg38wSUY2mmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6"
      ],
      "metadata": {
        "id": "89xgQB852qQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Challenge Question :Real-Time Object Count & Alert System**"
      ],
      "metadata": {
        "id": "rtQnfyYV20v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q: Create a system that detects and counts specific objects in real-time using your webcam — and triggers an alert when the count exceeds a certain limit.\n",
        "\n",
        "1. Load a pre-trained object detection model (e.g. MobileNet-SSD).\n",
        "\n",
        "2. Open the webcam using cv2.VideoCapture.\n",
        "\n",
        "3. For each frame:\n",
        "\n",
        " - Detect objects using the model.\n",
        "\n",
        " - Filter detections for a specific class (e.g. \"person\").\n",
        "\n",
        " - Count how many of that object are currently visible.\n",
        "\n",
        "4. Display the count on screen in real-time.\n",
        "\n",
        "5. If the count exceeds a set threshold (e.g. more than 3 people):\n",
        "\n",
        "  - Trigger an alert (e.g. play a sound or show a warning message).\n",
        "\n",
        "6. Exit the program when ESC is pressed.\n",
        "\n"
      ],
      "metadata": {
        "id": "hiXalgUq3EUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter code here"
      ],
      "metadata": {
        "id": "XMP2HDof3siH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **good luck ;)**"
      ],
      "metadata": {
        "id": "BURURoZY7pSU"
      }
    }
  ]
}